import os
import json
import random
import requests
import facebook
import google.generativeai as genai
from bs4 import BeautifulSoup
from googlesearch import search
from urllib.parse import urljoin
from dotenv import load_dotenv
from google.api_core import exceptions as google_exceptions

# --- Load biáº¿n mÃ´i trÆ°á»ng ---
load_dotenv()

# --- Cáº¥u hÃ¬nh toÃ n cá»¥c ---
GEMINI_API_KEYS_LIST = [key.strip() for key in os.getenv("GEMINI_API_KEYS", "").split(',') if key.strip()]
FB_PAGE_ID = os.getenv("FB_PAGE_ID")
FB_PAGE_ACCESS_TOKEN = os.getenv("FB_PAGE_ACCESS_TOKEN")
BACKEND_API_URL_FOR_TOPIC = os.getenv("BACKEND_CATEGORIES_LIST_API_URL")
KEY_INDEX_FILE = 'gemini_key_index.txt'


def get_random_topic_from_api():
    if not BACKEND_API_URL_FOR_TOPIC:
        print("âŒ Agent: Biáº¿n mÃ´i trÆ°á»ng BACKEND_CATEGORIES_LIST_API_URL chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh.")
        return None

    try:
        response = requests.get(BACKEND_API_URL_FOR_TOPIC, timeout=10)
        response.raise_for_status()
        data = response.json()

        if isinstance(data, dict) and "name" in data:
            return data.get("name")
        elif isinstance(data, dict) and "data" in data and isinstance(data["data"], list) and data["data"]:
            return random.choice(data["data"]).get("name")

        print(f"âŒ Agent: KhÃ´ng thá»ƒ láº¥y chá»§ Ä‘á» tá»« JSON: {data}")
        return None
    except Exception as e:
        print(f"âŒ Agent: Lá»—i gá»i API láº¥y chá»§ Ä‘á»: {e}")
        return None


def search_google_and_scrape(query: str, num_results: int = 20):
    print(f"\nğŸ” Agent: Báº¯t Ä‘áº§u cÃ o dá»¯ liá»‡u cho '{query}'...")
    try:
        initial_links = list(search(query, num_results=num_results, lang='vi'))
        if not initial_links:
            return []

        article_links_to_scrape = set()
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...'}

        for link in initial_links:
            if any(keyword in link for keyword in ['.html', '/chi-tiet/', '/post/', '/bai-viet/']):
                article_links_to_scrape.add(link)
                continue

            try:
                response = requests.get(link, headers=headers, timeout=10, verify=False)
                soup = BeautifulSoup(response.text, 'html.parser')
                for a_tag in soup.find_all('a', href=True):
                    potential_article_url = urljoin(link, a_tag['href'])
                    if any(keyword in potential_article_url for keyword in ['.html', '/chi-tiet/', '/post/', '/bai-viet/']):
                        article_links_to_scrape.add(potential_article_url)
            except requests.RequestException:
                pass

        if not article_links_to_scrape:
            return []

        scraped_results = []
        image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.webp')

        for article_link in list(article_links_to_scrape)[:num_results]:
            try:
                response = requests.get(article_link, headers=headers, timeout=15, verify=False)
                soup = BeautifulSoup(response.text, 'html.parser')
                content = "\n".join(p.get_text().strip() for p in soup.find_all("p") if p.get_text().strip())
                if not content:
                    continue

                image_url = None
                og_tag = soup.find("meta", property="og:image")
                if og_tag and og_tag.get("content"):
                    potential_url = urljoin(article_link, og_tag["content"])
                    if potential_url.lower().endswith(image_extensions):
                        image_url = potential_url

                if not image_url:
                    first_img_tag = soup.find("img")
                    if first_img_tag and first_img_tag.get("src"):
                        potential_url = urljoin(article_link, first_img_tag["src"])
                        if potential_url.lower().endswith(image_extensions):
                            image_url = potential_url

                scraped_results.append({"link": article_link, "content": content, "image_url": image_url})
            except requests.RequestException as error:
                print(f"         -> Lá»—i khi cÃ o ná»™i dung: {error}")

        print(f"âœ… Agent: ÄÃ£ cÃ o thÃ nh cÃ´ng {len(scraped_results)} bÃ i viáº¿t.")
        return scraped_results
    except Exception as error:
        print(f"âŒ Agent: Lá»—i nghiÃªm trá»ng khi cÃ o dá»¯ liá»‡u: {error}")
        return []


def get_start_key_index():
    try:
        with open(KEY_INDEX_FILE, 'r') as f:
            idx = int(f.read().strip())
    except (FileNotFoundError, ValueError):
        idx = 0
    if GEMINI_API_KEYS_LIST:
        with open(KEY_INDEX_FILE, 'w') as f:
            f.write(str((idx + 1) % len(GEMINI_API_KEYS_LIST)))
    return idx


def rewrite_and_decide_with_gemini(article_list, topic):
    if not article_list or not GEMINI_API_KEYS_LIST:
        return None

    combined_info = "\n".join(
        f"\n--- BÃ€I VIáº¾T {i+1} ---\nNá»˜I DUNG: {a['content']}\náº¢NH Äá»€ XUáº¤T: {a.get('image_url', 'KhÃ´ng cÃ³')}"
        for i, a in enumerate(article_list)
    )

    prompt = f"""
Báº¡n lÃ  má»™t AI biÃªn táº­p viÃªn chuyÃªn nghiá»‡p cho Fanpage Facebook.
Dá»±a trÃªn cÃ¡c bÃ i viáº¿t sau vá» chá»§ Ä‘á» '{topic}', hÃ£y thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ sau:

1.  **VIáº¾T BÃ€I:** SÃ¡ng táº¡o má»™t bÃ i Ä‘Äƒng Facebook DUY NHáº¤T, dÃ i khoáº£ng 250-400 tá»«, vá»›i giá»ng vÄƒn chuyÃªn nghiá»‡p, sÃ¢u sáº¯c. Cuá»‘i bÃ i thÃªm 3-5 hashtag liÃªn quan.
2.  **CHá»ŒN áº¢NH:** Tá»« danh sÃ¡ch \"áº¢NH Äá»€ XUáº¤T\", hÃ£y chá»n ra **DUY NHáº¤T Má»˜T (1)** áº£nh mÃ  báº¡n cho lÃ  Ä‘áº¹p vÃ  phÃ¹ há»£p nháº¥t Ä‘á»ƒ lÃ m áº£nh Ä‘áº¡i diá»‡n cho bÃ i viáº¿t. Náº¿u khÃ´ng cÃ³ áº£nh nÃ o phÃ¹ há»£p, hÃ£y tráº£ vá» má»™t danh sÃ¡ch rá»—ng `[]`.

**YÃŠU Cáº¦U Äáº¦U RA (Ráº¤T QUAN TRá»ŒNG):**
Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng má»™t chuá»—i JSON há»£p lá»‡, khÃ´ng cÃ³ báº¥t ká»³ vÄƒn báº£n giáº£i thÃ­ch nÃ o khÃ¡c.

**Cáº¤U TRÃšC JSON Báº®T BUá»˜C:**
```json
{{
  "facebook_post": "Ná»™i dung bÃ i viáº¿t Facebook báº¡n Ä‘Ã£ táº¡o...",
  "chosen_image_urls": ["url_anh_duy_nhat_ban_da_chon.jpg"]
}}
Dá»® LIá»†U Äáº¦U VÃ€O:
{combined_info}
"""

    start_index = get_start_key_index()
    for i in range(len(GEMINI_API_KEYS_LIST)):
        key_index = (start_index + i) % len(GEMINI_API_KEYS_LIST)
        api_key = GEMINI_API_KEYS_LIST[key_index].strip()
        if not api_key:
            continue

        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            cleaned_response = response.text.strip().lstrip("```json").rstrip("```").strip()
            return cleaned_response
        except google_exceptions.ResourceExhausted:
            print(f"âš ï¸ Key {key_index+1} háº¿t háº¡n má»©c. Thá»­ key khÃ¡c...")
        except Exception as e:
            print(f"âŒ Lá»—i AI vá»›i key {key_index+1}: {e}")

    return None


def post_to_facebook(message: str, image_urls: list = None):
    if not FB_PAGE_ID or not FB_PAGE_ACCESS_TOKEN:
        return False, "Thiáº¿u cáº¥u hÃ¬nh Facebook."

    try:
        graph = facebook.GraphAPI(access_token=FB_PAGE_ACCESS_TOKEN)

        if image_urls and isinstance(image_urls, list) and len(image_urls) > 0:
            first_image_url = image_urls[0]
            print(f"\nğŸš€ Agent: Chuáº©n bá»‹ Ä‘Äƒng bÃ i kÃ¨m 1 áº£nh: {first_image_url}")
            try:
                graph.put_photo(image=requests.get(first_image_url).content, message=message, album_path=f"{FB_PAGE_ID}/photos")
                print("   -> ÄÄƒng thÃ nh cÃ´ng!")
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi táº£i vÃ  Ä‘Äƒng áº£nh {first_image_url}: {e}")
                return False, "Lá»—i khi Ä‘Äƒng áº£nh."
        else:
            print("\nğŸš€ Agent: Chuáº©n bá»‹ Ä‘Äƒng bÃ i viáº¿t chá»¯...")
            graph.put_object(parent_object=FB_PAGE_ID, connection_name="feed", message=message)

        return True, f"https://www.facebook.com/{FB_PAGE_ID}"
    except Exception as e:
        return False, str(e)


def generate_and_post_article():
    try:
        topic = get_random_topic_from_api()
        if not topic:
            return {"status": False, "message": "KhÃ´ng láº¥y Ä‘Æ°á»£c chá»§ Ä‘á»."}

        articles = search_google_and_scrape(topic)
        if not articles:
            return {"status": False, "message": "KhÃ´ng tÃ¬m tháº¥y ná»™i dung tá»« Google."}

        ai_json_string = rewrite_and_decide_with_gemini(articles, topic)
        if not ai_json_string:
            return {"status": False, "message": "AI khÃ´ng tráº£ vá» ná»™i dung."}

        try:
            parsed_data = json.loads(ai_json_string)
            post_message = parsed_data.get("facebook_post", "")
            image_urls = parsed_data.get("chosen_image_urls", [])
        except json.JSONDecodeError:
            post_message = ai_json_string
            image_urls = []

        if not post_message:
            return {"status": False, "message": "Ná»™i dung AI tráº£ vá» bá»‹ rá»—ng."}

        is_success, result_message = post_to_facebook(post_message, image_urls)
        return {
            "status": is_success,
            "message": "ÄÄƒng thÃ nh cÃ´ng!" if is_success else f"Lá»—i: {result_message}",
            "post_url": result_message if is_success else None,
            "content": post_message
        }
    except Exception as e:
        return {"status": False, "message": f"Lá»—i há»‡ thá»‘ng: {e}"}
